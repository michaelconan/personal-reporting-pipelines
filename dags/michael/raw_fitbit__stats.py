"""
raw_fitbit__stats.py

DAGs to load data from FitBit using Web API.

OAuth2 access and refresh token can be generated by following this `tutorial`_.

.. _tutorial: https://dev.fitbit.com/build/reference/web-api/troubleshooting-guide/oauth2-tutorial/
"""

# Basic imports
import os
import json
import jsonlines
import pendulum

# Standard airflow imports
from airflow.decorators import task
from airflow.models import DAG
from airflow.datasets import Dataset

# Airflow hooks and operators
from airflow.hooks.base import BaseHook

# Common custom tasks
from michael.common.bigquery import load_file_to_bq
from michael.datasets import (
    FITBIT_SLEEP_DS,
)

IS_TEST = os.getenv("TEST") or os.getenv("CI")

# Fitbit connection
FITBIT_CONN_ID = "fitbit_app"

# BigQuery connection details
BQ_CONN_ID = "bigquery_reporting"
BQ_SLEEP_TABLE = "fitbit__sleep"

OBJECT_KEY = {
    "sleep": {
        "day_range": 100,
        "properties": [
            "logId",
            "dateOfSleep",
            "duration",
            "startTime",
            "endTime",
            "logType",
            "type",
        ],
    }
}

DAG_CONFIGS = [
    {
        "dag_id": "raw_fitbit__sleep__full",
        "schedule": "@once",
        "resource": "sleep",
        "bq_table": BQ_SLEEP_TABLE,
        "dataset": FITBIT_SLEEP_DS,
    },
    {
        "dag_id": "raw_fitbit__sleep__period",
        "schedule": "@daily",
        "resource": "sleep",
        "bq_table": BQ_SLEEP_TABLE,
        "dataset": FITBIT_SLEEP_DS,
    },
]


def create_fitbit_dag(
    dag_id: str,
    schedule: str,
    bq_table: str,
    dataset: Dataset,
    resource: str,
) -> DAG:
    with DAG(
        dag_id,
        schedule=schedule,
        start_date=pendulum.datetime(2024, 10, 1),
        catchup=False,
        params={"raw_schema": "raw"},
        user_defined_macros={"BQ_TABLE": bq_table},
        tags=["fitbit", "health", "raw"],
    ) as dag:
        DATA_FILE = f"/tmp/{dag_id}.jsonl"
        object_info = OBJECT_KEY[resource]

        @task(
            task_id="get_fitbit_data",
        )
        def get_fitbit_data(
            conn_id: str,
            resource: str,
            data_interval_start: pendulum.DateTime,
            data_interval_end: pendulum.DateTime,
        ) -> int:
            """Get data from FitBit API and write to JSONL file.

            This function connects to the FitBit API using OAuth2 credentials.

            Args:
                conn_id (str): Airflow connection identifier for Fitbit API key
                resource (str): Fitbit resource to query (e.g., sleep, steps)
                data_interval_start (pendulum.DateTime): Start of interval, from context
                data_interval_end (pendulum.DateTime): End of interval, from context

            Returns:
                int: Rows returned from Fitbit API
            """

            import fitbit

            # Get day range from object_info
            day_range = object_info["day_range"]

            # Connect to Hubspot API
            connection = BaseHook.get_connection(conn_id)

            def update_connection_tokens(token: dict):
                """Update the connection with new access and refresh tokens
                when authentication is refreshed.

                Args:
                    token (dict): The new access and refresh tokens
                """
                connection.extra_dejson["access_token"] = token["access_token"]
                connection.extra_dejson["refresh_token"] = token["refresh_token"]
                connection.set_extra(json.dumps(connection.extra_dejson))

            # Create a FitBit client connection
            client = fitbit.Fitbit(
                client_id=connection.login,
                client_secret=connection.password,
                oauth2=True,
                access_token=connection.extra_dejson["access_token"],
                refresh_token=connection.extra_dejson["refresh_token"],
                refresh_cb=update_connection_tokens,
            )

            # Get activity log by date range
            all_data = list()
            base_date = data_interval_start
            while base_date <= data_interval_end:
                # Determine the end of the current range
                compare_date = min(base_date.add(days=day_range), data_interval_end)

                # Query FitBit data within range and append to list
                page_data = client.time_series(
                    resource, base_date=base_date, end_date=compare_date
                )
                all_data.extend(page_data[resource])

                if IS_TEST:
                    # For testing, break after the first range
                    break

                # Move to the next range
                base_date = compare_date.add(days=1)

            # Select specific properties from the data
            results = {
                k: v
                for row in all_data
                for k, v in row.items()
                if k in object_info["properties"]
            }

            if results:
                # Write data to a JSONL file
                with jsonlines.open(DATA_FILE, mode="w") as writer:
                    writer.writeall(results)

            return len(results)

        @task(
            task_id="load_file_to_bq",
            outlets=[dataset],
        )
        def load_data_file(rows: int, params: dict, outlet_events=None):
            if rows > 0:
                job_state = load_file_to_bq(
                    conn_id=BQ_CONN_ID,
                    file_path=DATA_FILE,
                    table_id=f"{params['raw_schema']}.{bq_table}",
                )
                # Update outlet dataset extras
                outlet_events[dataset].extra = {
                    "state": job_state,
                    "rows": rows,
                }

        # Define task flow - task functions must be called ()
        fitbit_data = get_fitbit_data(
            conn_id=FITBIT_CONN_ID,
            resource=resource,
        )
        load_data_file(fitbit_data)

        return dag


# Create DAGs dynamically
for config in DAG_CONFIGS:
    globals()[config["dag_id"]] = create_fitbit_dag(**config)
